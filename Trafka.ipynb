{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install faker\n",
        "!pip install confluent_kafka"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iS6jVsPSITeO",
        "outputId": "ced7875b-0e0c-4142-fcae-dc8e22b37ee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading Faker-23.2.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from faker) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
            "Installing collected packages: faker\n",
            "Successfully installed faker-23.2.1\n",
            "Collecting confluent_kafka\n",
            "  Downloading confluent_kafka-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: confluent_kafka\n",
            "Successfully installed confluent_kafka-2.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from faker import Faker\n",
        "from confluent_kafka import Producer\n",
        "import json\n",
        "\n",
        "fake = Faker()\n",
        "\n",
        "bootstrap_servers = 'pkc-4r087.us-west2.gcp.confluent.cloud:9092'\n",
        "sasl_plain_username = 'ZI565VPJU4RFGXOK'\n",
        "sasl_plain_password = 'Vo96TdSbLJafQGbtMyii8IqAb7BPlQ3S++iR7awRblJAl1XyJWXbL+WGZcCdO8bA'\n",
        "topic_name = 'TrafficUpdate'\n",
        "\n",
        "# Create the Kafka producer\n",
        "producer_config = {\n",
        "    'bootstrap.servers': bootstrap_servers,\n",
        "    'security.protocol': 'SASL_SSL',\n",
        "    'sasl.mechanisms': 'PLAIN',\n",
        "    'sasl.username': sasl_plain_username,\n",
        "    'sasl.password': sasl_plain_password,\n",
        "}\n",
        "\n",
        "producer = Producer(producer_config)\n",
        "\n",
        "\n",
        "def delivery_report(err, msg):\n",
        "    if err is not None:\n",
        "        print('Message delivery failed: {}'.format(err))\n",
        "    else:\n",
        "        print('Message delivered to topic {} [partition {}] at offset {}'.format(msg.topic(), msg.partition(), msg.offset()))\n",
        "\n",
        "\n",
        "def get_registered_users():\n",
        "    return {\n",
        "        \"name\": fake.name(),\n",
        "        \"address\": fake.address(),\n",
        "        \"message\": fake.text(),\n",
        "        \"created_on\": fake.year()\n",
        "    }\n",
        "\n",
        "while True:\n",
        "    user = get_registered_users()\n",
        "\n",
        "    # Convert user data to JSON format\n",
        "    user_json = json.dumps(user)\n",
        "\n",
        "    # Produce the message to Kafka\n",
        "    producer.produce(topic_name, user_json, callback=delivery_report)\n",
        "    producer.flush()  # Ensure message is sent\n",
        "\n",
        "    time.sleep(30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTDKJiFRHqgN",
        "outputId": "5aa76331-b89f-4a93-fe2a-1584cf4ee58f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message delivered to topic TrafficUpdate [partition 2] at offset 12\n",
            "Message delivered to topic TrafficUpdate [partition 5] at offset 18\n",
            "Message delivered to topic TrafficUpdate [partition 3] at offset 19\n",
            "Message delivered to topic TrafficUpdate [partition 4] at offset 15\n",
            "Message delivered to topic TrafficUpdate [partition 4] at offset 16\n",
            "Message delivered to topic TrafficUpdate [partition 1] at offset 9\n",
            "Message delivered to topic TrafficUpdate [partition 5] at offset 19\n",
            "Message delivered to topic TrafficUpdate [partition 2] at offset 13\n",
            "Message delivered to topic TrafficUpdate [partition 5] at offset 20\n",
            "Message delivered to topic TrafficUpdate [partition 1] at offset 10\n",
            "Message delivered to topic TrafficUpdate [partition 1] at offset 11\n",
            "Message delivered to topic TrafficUpdate [partition 2] at offset 14\n",
            "Message delivered to topic TrafficUpdate [partition 2] at offset 15\n",
            "Message delivered to topic TrafficUpdate [partition 1] at offset 12\n",
            "Message delivered to topic TrafficUpdate [partition 5] at offset 21\n",
            "Message delivered to topic TrafficUpdate [partition 5] at offset 22\n",
            "Message delivered to topic TrafficUpdate [partition 4] at offset 17\n",
            "Message delivered to topic TrafficUpdate [partition 2] at offset 16\n",
            "Message delivered to topic TrafficUpdate [partition 0] at offset 22\n",
            "Message delivered to topic TrafficUpdate [partition 1] at offset 13\n",
            "Message delivered to topic TrafficUpdate [partition 4] at offset 18\n",
            "Message delivered to topic TrafficUpdate [partition 5] at offset 23\n",
            "Message delivered to topic TrafficUpdate [partition 5] at offset 24\n",
            "Message delivered to topic TrafficUpdate [partition 0] at offset 23\n",
            "Message delivered to topic TrafficUpdate [partition 2] at offset 17\n",
            "Message delivered to topic TrafficUpdate [partition 3] at offset 20\n",
            "Message delivered to topic TrafficUpdate [partition 3] at offset 21\n",
            "Message delivered to topic TrafficUpdate [partition 4] at offset 19\n",
            "Message delivered to topic TrafficUpdate [partition 0] at offset 24\n",
            "Message delivered to topic TrafficUpdate [partition 4] at offset 20\n",
            "Message delivered to topic TrafficUpdate [partition 2] at offset 18\n",
            "Message delivered to topic TrafficUpdate [partition 3] at offset 22\n",
            "Message delivered to topic TrafficUpdate [partition 2] at offset 19\n",
            "Message delivered to topic TrafficUpdate [partition 4] at offset 21\n",
            "Message delivered to topic TrafficUpdate [partition 3] at offset 23\n",
            "Message delivered to topic TrafficUpdate [partition 0] at offset 25\n",
            "Message delivered to topic TrafficUpdate [partition 1] at offset 14\n",
            "Message delivered to topic TrafficUpdate [partition 4] at offset 22\n",
            "Message delivered to topic TrafficUpdate [partition 1] at offset 15\n",
            "Message delivered to topic TrafficUpdate [partition 0] at offset 26\n",
            "Message delivered to topic TrafficUpdate [partition 0] at offset 27\n",
            "Message delivered to topic TrafficUpdate [partition 4] at offset 23\n",
            "Message delivered to topic TrafficUpdate [partition 2] at offset 20\n",
            "Message delivered to topic TrafficUpdate [partition 0] at offset 28\n",
            "Message delivered to topic TrafficUpdate [partition 4] at offset 24\n",
            "Message delivered to topic TrafficUpdate [partition 2] at offset 21\n",
            "Message delivered to topic TrafficUpdate [partition 4] at offset 25\n",
            "Message delivered to topic TrafficUpdate [partition 0] at offset 29\n",
            "Message delivered to topic TrafficUpdate [partition 5] at offset 25\n",
            "Message delivered to topic TrafficUpdate [partition 4] at offset 26\n",
            "Message delivered to topic TrafficUpdate [partition 2] at offset 22\n",
            "Message delivered to topic TrafficUpdate [partition 0] at offset 30\n",
            "Message delivered to topic TrafficUpdate [partition 4] at offset 27\n",
            "Message delivered to topic TrafficUpdate [partition 1] at offset 16\n",
            "Message delivered to topic TrafficUpdate [partition 3] at offset 24\n",
            "Message delivered to topic TrafficUpdate [partition 1] at offset 17\n",
            "Message delivered to topic TrafficUpdate [partition 2] at offset 23\n",
            "Message delivered to topic TrafficUpdate [partition 0] at offset 31\n",
            "Message delivered to topic TrafficUpdate [partition 1] at offset 18\n",
            "Message delivered to topic TrafficUpdate [partition 4] at offset 28\n",
            "Message delivered to topic TrafficUpdate [partition 2] at offset 24\n",
            "Message delivered to topic TrafficUpdate [partition 1] at offset 19\n",
            "Message delivered to topic TrafficUpdate [partition 5] at offset 26\n",
            "Message delivered to topic TrafficUpdate [partition 0] at offset 32\n",
            "Message delivered to topic TrafficUpdate [partition 0] at offset 33\n",
            "Message delivered to topic TrafficUpdate [partition 1] at offset 20\n",
            "Message delivered to topic TrafficUpdate [partition 2] at offset 25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from confluent_kafka import Consumer, KafkaError\n",
        "import json\n",
        "\n",
        "bootstrap_servers = 'pkc-4r087.us-west2.gcp.confluent.cloud:9092'\n",
        "sasl_plain_username = 'ZI565VPJU4RFGXOK'\n",
        "sasl_plain_password = 'Vo96TdSbLJafQGbtMyii8IqAb7BPlQ3S++iR7awRblJAl1XyJWXbL+WGZcCdO8bA'\n",
        "oup_id = 'my_consumer_group'\n",
        "topic_name = 'TrafficUpdate'\n",
        "\n",
        "csv_file_path = 'received_users.csv'\n",
        "\n",
        "# Create the Kafka consumer\n",
        "consumer_config = {\n",
        "    'bootstrap.servers': bootstrap_servers,\n",
        "    'group.id': group_id,\n",
        "    'security.protocol': 'SASL_SSL',\n",
        "    'sasl.mechanisms': 'PLAIN',\n",
        "    'sasl.username': sasl_plain_username,\n",
        "    'sasl.password': sasl_plain_password,\n",
        "    'auto.offset.reset': 'earliest',\n",
        "}\n",
        "\n",
        "consumer = Consumer(consumer_config)\n",
        "consumer.subscribe([topic_name])\n",
        "\n",
        "try:\n",
        "    with open(csv_file_path, 'a', newline='', encoding='utf-8') as csv_file:\n",
        "        csv_writer = csv.writer(csv_file)\n",
        "\n",
        "        while True:\n",
        "            msg = consumer.poll(1.0)\n",
        "\n",
        "            if msg is None:\n",
        "                continue\n",
        "            if msg.error():\n",
        "                if msg.error().code() == KafkaError._PARTITION_EOF:\n",
        "                    continue\n",
        "                else:\n",
        "                    print('Error: {}'.format(msg.error()))\n",
        "                    break\n",
        "\n",
        "            try:\n",
        "                user_json = json.loads(msg.value().decode('utf-8'))\n",
        "                # Write the user data to the CSV file\n",
        "                csv_writer.writerow([user_json['name'], user_json['address'], user_json['message'], user_json['created_on']])\n",
        "                print(\"Received and recorded user:\", user_json)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print('Error decoding JSON: {}'.format(e))\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    pass\n",
        "finally:\n",
        "    consumer.close()\n"
      ],
      "metadata": {
        "id": "HmpzZLM1nA4G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}